{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNetArchitecture.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-mazurkiewicz/PWR_MachineLearning/blob/AlexNet_master/AlexNetArchitecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VRCb-uQ9KsQR",
        "colab_type": "code",
        "outputId": "5a5b33f3-cbf9-427a-c235-e62c82bba1cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D , MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc=TensorBoardColab()\n",
        "\n",
        "import sys\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, save_img\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.io as io\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://40fb51bd.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "29MMZ4CS6tXg",
        "colab_type": "code",
        "outputId": "1bf06503-d12b-44d2-e6d9-d07a316cec79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qgWnboSD6Y4z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_of_classes = 4\n",
        "base_dir_processed = '/content/gdrive/My Drive/PWr_AlexNet_data/processed/'\n",
        "data_set = 'no-padding/resize/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9pPGX8nC65BL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_gen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    brightness_range=(0.5,1.5),\n",
        "    shear_range=0.01,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.1\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRPOZTkP68yk",
        "colab_type": "code",
        "outputId": "64080694-d34e-4088-c44b-7f8eafcc47fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "number_of_images_for_fit = 100\n",
        "\n",
        "all_images = []\n",
        "for class_name in os.listdir(base_dir_processed + data_set + 'train'):\n",
        "  for image_path in tqdm(os.listdir(base_dir_processed + data_set + 'train/' + class_name)[:number_of_images_for_fit]):\n",
        "    img = io.imread(base_dir_processed + data_set + 'train/' + class_name + '/' + image_path)\n",
        "    all_images.append(img)\n",
        "x_train = np.array(all_images)\n",
        "\n",
        "image_gen.fit(x_train)\n",
        "\n",
        "generator = image_gen.flow_from_directory(\n",
        "    base_dir_processed + data_set + '/' + 'train',\n",
        "        target_size=(227,227),\n",
        "        batch_size=128,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 271.16it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 306.60it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 318.42it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 310.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 5213 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MY61cKO5GcBL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_gen_test = ImageDataGenerator()\n",
        "test_generator = image_gen_test.flow_from_directory(\n",
        "    base_dir_processed + data_set + '/' + 'test',\n",
        "        target_size=(227,227),\n",
        "        batch_size=128,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qr03ZNAGeWh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#1st approach"
      ]
    },
    {
      "metadata": {
        "id": "NWXMrtHWKwYl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6eVYowfLFiQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zH8SxHyMn2Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZtwlZ_1NEDU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JPSjxDO5NEwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wpCvpYLCNQbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2qLH-ZMN56Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yt6gnb7TN6qq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrisShUrQEQM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgNpjftqQQPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(num_of_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8nGQMS1p5ax3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fuh1GeN3BZ3O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qqb4G6Kj5O0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hist = model.fit(X_tr, y_tr, validation_data = (X_val, y_val), epochs=10, callbacks=[TensorBoardColabCallback(tbc)])#000, batch_size=1000)\n",
        "#To fit the model: , callbacks=[TensorBoardColabCallback(tbc)]\n",
        "# hist = model.fit_generator(generator, steps_per_epoch=1, epochs=10, verbose=1, callbacks=[TensorBoardColabCallback(tbc)])\n",
        "hist = model.fit_generator(generator, samples_per_epoch=10, epochs=80, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nUW5_OioH1-C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#3rd approach\n"
      ]
    },
    {
      "metadata": {
        "id": "bBNvWVOeH4Rx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2937
        },
        "outputId": "0faf9978-3e80-4d61-bd9a-aea08933549a"
      },
      "cell_type": "code",
      "source": [
        "# (1) Importing dependency\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
        " Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "# (2) Get Data\n",
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "x, y = oxflower17.load_data(one_hot=True)\n",
        "\n",
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# # 3rd Dense Layer\n",
        "# model.add(Dense(1000))\n",
        "# model.add(Activation('relu'))\n",
        "# # Add Dropout\n",
        "# model.add(Dropout(0.4))\n",
        "# # Batch Normalisation\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\\\n",
        " metrics=['accuracy'])\n",
        "\n",
        "# (5) Train\n",
        "model.fit(x, y, batch_size=64, epochs=50, verbose=1, \\\n",
        "validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 54, 54, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 26, 26, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 26, 26, 256)       614656    \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 26, 26, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 12, 12, 384)       885120    \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 12, 12, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 12, 12, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 12, 12, 256)       884992    \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4096)              26218496  \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 17)                69649     \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 46,834,449\n",
            "Trainable params: 46,825,553\n",
            "Non-trainable params: 8,896\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/50\n",
            "1088/1088 [==============================] - 6s 6ms/step - loss: 3.4109 - acc: 0.0882 - val_loss: 12.8149 - val_acc: 0.0404\n",
            "Epoch 2/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.9651 - acc: 0.1131 - val_loss: 7.1204 - val_acc: 0.0846\n",
            "Epoch 3/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.8554 - acc: 0.1232 - val_loss: 3.3130 - val_acc: 0.1213\n",
            "Epoch 4/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.7002 - acc: 0.1645 - val_loss: 4.3320 - val_acc: 0.1324\n",
            "Epoch 5/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.5719 - acc: 0.1636 - val_loss: 3.1859 - val_acc: 0.1360\n",
            "Epoch 6/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.4916 - acc: 0.2031 - val_loss: 3.1834 - val_acc: 0.1912\n",
            "Epoch 7/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.4538 - acc: 0.2068 - val_loss: 3.0013 - val_acc: 0.2169\n",
            "Epoch 8/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.3461 - acc: 0.2261 - val_loss: 2.9267 - val_acc: 0.1765\n",
            "Epoch 9/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.2294 - acc: 0.2546 - val_loss: 2.1960 - val_acc: 0.2574\n",
            "Epoch 10/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.5371 - acc: 0.2215 - val_loss: 10.1642 - val_acc: 0.0588\n",
            "Epoch 11/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.4065 - acc: 0.2077 - val_loss: 11.0922 - val_acc: 0.0588\n",
            "Epoch 12/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.1547 - acc: 0.2665 - val_loss: 6.6976 - val_acc: 0.1471\n",
            "Epoch 13/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 2.0149 - acc: 0.3199 - val_loss: 9.3121 - val_acc: 0.1434\n",
            "Epoch 14/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.9256 - acc: 0.3456 - val_loss: 8.4943 - val_acc: 0.1213\n",
            "Epoch 15/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.8836 - acc: 0.3695 - val_loss: 3.8235 - val_acc: 0.2132\n",
            "Epoch 16/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.8778 - acc: 0.3612 - val_loss: 7.6039 - val_acc: 0.1654\n",
            "Epoch 17/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.6995 - acc: 0.3971 - val_loss: 6.4589 - val_acc: 0.1654\n",
            "Epoch 18/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.6163 - acc: 0.4531 - val_loss: 3.5770 - val_acc: 0.2574\n",
            "Epoch 19/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.5143 - acc: 0.4789 - val_loss: 2.2486 - val_acc: 0.3640\n",
            "Epoch 20/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.5371 - acc: 0.4733 - val_loss: 6.1255 - val_acc: 0.2500\n",
            "Epoch 21/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.7143 - acc: 0.4182 - val_loss: 3.2203 - val_acc: 0.3566\n",
            "Epoch 22/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.4947 - acc: 0.4982 - val_loss: 1.8940 - val_acc: 0.4375\n",
            "Epoch 23/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.3625 - acc: 0.5386 - val_loss: 2.2562 - val_acc: 0.4044\n",
            "Epoch 24/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.6940 - acc: 0.4246 - val_loss: 2.8020 - val_acc: 0.3676\n",
            "Epoch 25/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.4195 - acc: 0.5101 - val_loss: 2.2345 - val_acc: 0.3934\n",
            "Epoch 26/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.2285 - acc: 0.5689 - val_loss: 1.7455 - val_acc: 0.4596\n",
            "Epoch 27/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.1457 - acc: 0.6112 - val_loss: 1.6627 - val_acc: 0.4375\n",
            "Epoch 28/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 1.1003 - acc: 0.6186 - val_loss: 2.0825 - val_acc: 0.4191\n",
            "Epoch 29/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.9663 - acc: 0.6719 - val_loss: 2.4929 - val_acc: 0.3125\n",
            "Epoch 30/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.8926 - acc: 0.6847 - val_loss: 2.1957 - val_acc: 0.3603\n",
            "Epoch 31/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.8870 - acc: 0.6912 - val_loss: 2.0622 - val_acc: 0.4081\n",
            "Epoch 32/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.8297 - acc: 0.7114 - val_loss: 1.4688 - val_acc: 0.5662\n",
            "Epoch 33/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.7949 - acc: 0.7279 - val_loss: 2.0702 - val_acc: 0.3787\n",
            "Epoch 34/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.7597 - acc: 0.7436 - val_loss: 1.3592 - val_acc: 0.5478\n",
            "Epoch 35/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.7055 - acc: 0.7500 - val_loss: 1.2627 - val_acc: 0.5809\n",
            "Epoch 36/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.7152 - acc: 0.7564 - val_loss: 1.7341 - val_acc: 0.4853\n",
            "Epoch 37/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.8711 - acc: 0.6985 - val_loss: 1.9967 - val_acc: 0.4669\n",
            "Epoch 38/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.6649 - acc: 0.7785 - val_loss: 1.6850 - val_acc: 0.5441\n",
            "Epoch 39/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.5194 - acc: 0.8281 - val_loss: 1.4201 - val_acc: 0.6103\n",
            "Epoch 40/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.4574 - acc: 0.8465 - val_loss: 1.5316 - val_acc: 0.5993\n",
            "Epoch 41/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.4165 - acc: 0.8566 - val_loss: 1.3717 - val_acc: 0.6397\n",
            "Epoch 42/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.3768 - acc: 0.8686 - val_loss: 1.4611 - val_acc: 0.5625\n",
            "Epoch 43/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.3301 - acc: 0.8778 - val_loss: 1.5932 - val_acc: 0.5331\n",
            "Epoch 44/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.3391 - acc: 0.8759 - val_loss: 1.3759 - val_acc: 0.5956\n",
            "Epoch 45/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.4049 - acc: 0.8585 - val_loss: 1.8174 - val_acc: 0.4963\n",
            "Epoch 46/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.4292 - acc: 0.8548 - val_loss: 1.7002 - val_acc: 0.5074\n",
            "Epoch 47/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.3632 - acc: 0.8833 - val_loss: 2.7807 - val_acc: 0.5478\n",
            "Epoch 48/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.2619 - acc: 0.9062 - val_loss: 2.8955 - val_acc: 0.4559\n",
            "Epoch 49/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.2248 - acc: 0.9283 - val_loss: 2.0090 - val_acc: 0.5368\n",
            "Epoch 50/50\n",
            "1088/1088 [==============================] - 4s 3ms/step - loss: 0.2458 - acc: 0.9228 - val_loss: 2.0257 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f32b81c3da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "kmi8_GnxO121",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Test on our dataset"
      ]
    },
    {
      "metadata": {
        "id": "t7ppQWcMO0dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2094
        },
        "outputId": "7b0196cd-b91b-4fb2-b39e-b60d5f08eb27"
      },
      "cell_type": "code",
      "source": [
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11),strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(227*227*3,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# # 3rd Dense Layer\n",
        "# model.add(Dense(1000))\n",
        "# model.add(Activation('relu'))\n",
        "# # Add Dropout\n",
        "# model.add(Dropout(0.4))\n",
        "# # Batch Normalisation\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\\\n",
        " metrics=['accuracy'])\n",
        "\n",
        "# (5) Train\n",
        "hist = model.fit_generator(generator, samples_per_epoch=5213, epochs=50, verbose=1)\n",
        "# model.fit_generator(generator, batch_size=64, epochs=50, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 55, 55, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 55, 55, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 27, 27, 256)       614656    \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 27, 27, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 27, 27, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 13, 13, 384)       885120    \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 13, 13, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 13, 13, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 13, 13, 256)       884992    \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 4)                 16388     \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 58,315,524\n",
            "Trainable params: 58,306,628\n",
            "Non-trainable params: 8,896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=50, verbose=1, steps_per_epoch=40)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 95s 2s/step - loss: 1.5088 - acc: 0.4668\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 92s 2s/step - loss: 1.1281 - acc: 0.5501\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 92s 2s/step - loss: 1.0485 - acc: 0.5871\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 92s 2s/step - loss: 0.9287 - acc: 0.6237\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 92s 2s/step - loss: 0.8601 - acc: 0.6750\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 91s 2s/step - loss: 0.7871 - acc: 0.6978\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 88s 2s/step - loss: 0.7696 - acc: 0.7196\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 88s 2s/step - loss: 0.7238 - acc: 0.7377\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.6780 - acc: 0.7478\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 88s 2s/step - loss: 0.6841 - acc: 0.7496\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 86s 2s/step - loss: 0.5903 - acc: 0.7853\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 86s 2s/step - loss: 0.6151 - acc: 0.7746\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.5466 - acc: 0.7995\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.5229 - acc: 0.8002\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 86s 2s/step - loss: 0.6352 - acc: 0.7683\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 86s 2s/step - loss: 0.5765 - acc: 0.7902\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.5167 - acc: 0.8130\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 85s 2s/step - loss: 0.4666 - acc: 0.8273\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 86s 2s/step - loss: 0.4578 - acc: 0.8329\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.4128 - acc: 0.8444\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.4072 - acc: 0.8537\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.4245 - acc: 0.8425\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.4404 - acc: 0.8326\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.5621 - acc: 0.7914\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.4426 - acc: 0.8366\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 87s 2s/step - loss: 0.3777 - acc: 0.8618\n",
            "Epoch 27/50\n",
            "23/40 [================>.............] - ETA: 38s - loss: 0.3827 - acc: 0.8573"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}