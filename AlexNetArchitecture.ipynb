{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNetArchitecture.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-mazurkiewicz/PWR_MachineLearning/blob/AlexNet_master/AlexNetArchitecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VRCb-uQ9KsQR",
        "colab_type": "code",
        "outputId": "61e16f24-fcd4-4bf2-f83d-53a161d4daf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "  from keras.models import Sequential, load_model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D as Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc=TensorBoardColab()\n",
        "\n",
        "import sys\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, save_img\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.io as io\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://ce8aeb27.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "29MMZ4CS6tXg",
        "colab_type": "code",
        "outputId": "cd1995c6-d09f-432b-ce97-f4d163e01811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qgWnboSD6Y4z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_of_classes = 4\n",
        "base_dir_processed = '/content/gdrive/My Drive/PWr_AlexNet_data/processed/'\n",
        "data_set = 'no-padding/resize/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51WEd10Oj_0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "VALIDATION_SPLIT = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9pPGX8nC65BL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_gen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    brightness_range=(0.5,1.5),\n",
        "    shear_range=0.01,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        "    validation_split=VALIDATION_SPLIT\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRPOZTkP68yk",
        "colab_type": "code",
        "outputId": "2142235b-94dd-477c-dbfc-178cfb84378c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "number_of_images_for_fit = -1\n",
        "\n",
        "all_images = []\n",
        "for class_name in os.listdir(base_dir_processed + data_set + 'train'):\n",
        "  for image_path in tqdm(os.listdir(base_dir_processed + data_set + 'train/' + class_name)[:number_of_images_for_fit]):\n",
        "    img = io.imread(base_dir_processed + data_set + 'train/' + class_name + '/' + image_path)\n",
        "    all_images.append(img)\n",
        "x_train = np.array(all_images)\n",
        "\n",
        "image_gen.fit(x_train)\n",
        "\n",
        "generator = image_gen.flow_from_directory(\n",
        "    base_dir_processed + data_set + '/' + 'train',\n",
        "        target_size=(227,227),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "validation_generator = image_gen.flow_from_directory(\n",
        "    base_dir_processed + data_set + '/' + 'train',\n",
        "        target_size=(227,227),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='validation')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1298/1298 [00:05<00:00, 224.22it/s]\n",
            "100%|██████████| 1159/1159 [00:04<00:00, 234.48it/s]\n",
            "100%|██████████| 1643/1643 [00:06<00:00, 255.64it/s]\n",
            "100%|██████████| 1109/1109 [00:04<00:00, 252.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MY61cKO5GcBL",
        "colab_type": "code",
        "outputId": "1b30847e-c591-498f-8a70-1d92c3affea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# image_gen_val = ImageDataGenerator(featurewise_center=True)\n",
        "# image_gen_val.fit(x_train)\n",
        "# val_generator = image_gen_val.flow_from_directory(\n",
        "#     base_dir_processed + data_set + '/' + 'test',\n",
        "#         target_size=(227,227),\n",
        "#         batch_size=128,\n",
        "#         class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1304 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lUGCXB2fbDmR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Model"
      ]
    },
    {
      "metadata": {
        "id": "NWXMrtHWKwYl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6eVYowfLFiQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zH8SxHyMn2Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZtwlZ_1NEDU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JPSjxDO5NEwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wpCvpYLCNQbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2qLH-ZMN56Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yt6gnb7TN6qq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrisShUrQEQM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgNpjftqQQPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fuh1GeN3BZ3O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8nGQMS1p5ax3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qqb4G6Kj5O0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.001)\n",
        "hist = model.fit_generator(generator, steps_per_epoch=(5213*(1-VALIDATION_SPLIT)) // BATCH_SIZE, validation_data=validation_generator, validation_steps=4, epochs=100, verbose=1,\n",
        "                           callbacks=[reduce_lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EtxTPAmUbJwj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Model saving"
      ]
    },
    {
      "metadata": {
        "id": "EMe1HrhgzOCk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_dir_saving = '/content/gdrive/My Drive/PWr_AlexNet_models/'\n",
        "model_path = data_set + '{}/'.format(BATCH_SIZE)\n",
        "os.makedirs(base_dir_saving+model_path,  exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTHPVGCcP6iF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(base_dir_saving+model_path+'base_alexnet.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yVb8A_XdksB-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plotting"
      ]
    },
    {
      "metadata": {
        "id": "UT5S-AoVktJZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8), dpi=320)\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplots_adjust(hspace = .3)\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(212)\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.savefig(base_dir_saving+model_path+'base_alexnet.pdf')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}