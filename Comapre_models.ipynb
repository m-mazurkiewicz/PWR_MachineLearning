{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comapre_models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-mazurkiewicz/PWR_MachineLearning/blob/AlexNet_master/Comapre_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "h6Gjuh5k4MSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8cc9258-eef7-49ae-91db-b7d50dc8b28e"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "import skimage.io as io\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "iF9nHyuC4NO8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OWLayo2o422R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_dir_models = '/content/gdrive/My Drive/PWr_AlexNet_models/'\n",
        "base_dir_processed = '/content/gdrive/My Drive/PWr_AlexNet_data/processed/'\n",
        "number_of_images_for_fit = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RbO3qTvR9lWF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if os.path.isfile('/content/gdrive/My Drive/PWr_AlexNet_data/models_testing.pickle'):\n",
        "  models_testing = pickle.load('/content/gdrive/My Drive/PWr_AlexNet_data/models_testing.pickle')\n",
        "else:\n",
        "  models_testing = dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tQvyI1KY5ARW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in os.listdir(base_dir_models):\n",
        "  padding = i\n",
        "  for j in os.listdir(base_dir_models + i):\n",
        "    image_preprocess = j\n",
        "    for k in os.listdir(base_dir_models + i +'/' + j):\n",
        "      batch_size = k\n",
        "      for l in os.listdir(base_dir_models + i +'/' + j +'/' + k):\n",
        "        if 'h5' in l and l[:-3] not in models_testing.keys():\n",
        "          all_images = []\n",
        "          for class_name in os.listdir(base_dir_processed + '{0}/{1}'.format(padding,image_preprocess) + '/' + 'train'):\n",
        "            for image_path in tqdm(os.listdir(base_dir_processed + '{0}/{1}'.format(padding,image_preprocess) + '/' + 'train/' + class_name)[:number_of_images_for_fit]):\n",
        "              img = io.imread(base_dir_processed + '{0}/{1}'.format(padding,image_preprocess) + '/' + 'train/' + class_name + '/' + image_path)\n",
        "              all_images.append(img)\n",
        "          x_train = np.array(all_images)\n",
        "          del all_images\n",
        "          image_gen_test = ImageDataGenerator(featurewise_center=True)\n",
        "          image_gen_test.fit(x_train)\n",
        "          test_generator = image_gen_test.flow_from_directory(\n",
        "              base_dir_processed + '{0}/{1}'.format(padding,image_preprocess) + '/' + 'test',\n",
        "                  target_size=(227,227),\n",
        "                  batch_size=int(batch_size),\n",
        "                  class_mode='categorical')\n",
        "          model = keras.models.load_model(base_dir_models + i +'/' + j +'/' + k + '/' + l)\n",
        "          metrics = model.evaluate_generator(test_generator, steps=1304//int(batch_size))\n",
        "          models_testing[l.replace('.h5','')] = metrics[1]\n",
        "          del x_train\n",
        "          del model\n",
        "with open('/content/gdrive/My Drive/PWr_AlexNet_data/models_testing.pickle', 'wb') as f:\n",
        "  pickle.dump(models_testing, f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}